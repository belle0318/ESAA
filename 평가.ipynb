{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1C7tOC3_lCx-DFFnik7M2Jr4q04Mig61J",
      "authorship_tag": "ABX9TyN775R6qASSsxGX6P7KII0l"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Ch03. 평가**\n",
        "* 머신러닝은 데이터 가공/변환, 모델 학습/예측, 그리고 평가의 프로세스로 구성됨\n",
        "* 예측 성능을 평가하는 방법 : 성능평가지표(Evaluation Metric)\n",
        "  * 회귀 : 실제값과 예측값의 오차 평균값에 기반\n",
        "  * 분류 : 실제 결과 데이터와 예측 겨로가 데이터가 얼마나 정확하고 오류가 적게 발생하는가에 기반\n",
        "\n",
        "\n",
        "* 분류의 성능 평가 지표(이진/멀티, 이진에서 더욱 강조하는 지표)\n",
        "  * 정확도(Accuracy)\n",
        "  * 오차 행렬(Confusion Matrix)\n",
        "  * 정밀도(Precision)\n",
        "  * 재현율 (Recall)\n",
        "  * F1 score\n",
        "  * ROC AUC\n",
        "\n"
      ],
      "metadata": {
        "id": "qbhWHRzjANsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**01. 정확도(Accuracy)**\n",
        "- 정확도 = 예측 결과가 동일한 데이터 건수/ 전체 예측 데이터 건수\n",
        "- 정확도 지표가 어떻게 모델의 성능을 왜곡하는가?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "사이킷런의 BaseEstimator 클래스를 활용하여, 단순히 성별에 따라 생존자를 예측하는 단순한 분류기를 생성\n",
        "\n",
        "- 사이킷런의 BaseEsimators를 활용하면 Customized된 Estimator를 생성할 수 있음"
      ],
      "metadata": {
        "id": "a-qhH9FnB8XU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tgwu4PEfbUxd"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyDummyClassifier(BaseEstimator):\n",
        "  #fit()메서드는 아무것도 학습하지 않음\n",
        "  def fit(self, X, y=None):\n",
        "    pass\n",
        "  #predict() 메서드는 단순히 Sex 피처가 1이면 0, 그렇지 않으면 1로 예측함\n",
        "  def predict(self, X):\n",
        "    pred = np.zeros((X.shape[0],1))\n",
        "    for i in range(X.shape[0]):\n",
        "      if X['Sex'].iloc[i]==1:\n",
        "        pred[i]=0\n",
        "      else:\n",
        "        pred[i]=1\n",
        "    \n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MyDummyClassifier을 이용해 앞 장의 타이타닉 생존자 예측을 수행\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "#Null 처리 함수\n",
        "def fillna(df):\n",
        "  df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
        "  df['Cabin'].fillna('N',inplace=True)\n",
        "  df['Embarked'].fillna('N',inplace=True)\n",
        "  df['Fare'].fillna(0, inplace=True)\n",
        "  return df\n",
        "\n",
        "#머신러닝 알고리즘에 불필요한 속성제거\n",
        "def drop_features(df):\n",
        "  df.drop(['PassengerId','Name','Ticket'],axis=1, inplace=True)\n",
        "  return df\n",
        "\n",
        "#레이블 인코딩 수행\n",
        "def format_features(df):\n",
        "  df['Cabin'] = df['Cabin'].str[:1]\n",
        "  features = ['Cabin','Sex','Embarked']\n",
        "  for feature in features:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le = le.fit(df[feature])\n",
        "    df[feature] = le.transform(df[feature])\n",
        "  return df\n",
        "\n",
        "#앞에서 설정한 데이터 전처리 함수 호출\n",
        "def transform_features(df):\n",
        "  df = fillna(df)\n",
        "  df = drop_features(df)\n",
        "  df = format_features(df)\n",
        "  return df"
      ],
      "metadata": {
        "id": "efLtz56POy8o"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
        "titanic_df=pd.read_csv('/content/drive/MyDrive/ESAA/22-2/DATA/titanic_train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)\n",
        "\n",
        "# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행\n",
        "myclf=MyDummyClassifier()\n",
        "myclf.fit(X_train,y_train)\n",
        "\n",
        "mypredictions = myclf.predict(X_test)\n",
        "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test,mypredictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyeR4pwWFeGZ",
        "outputId": "0f6c5a01-71b0-42b7-b76e-059971ce89c1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy Classifier의 정확도는: 0.7877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> 단순 알고리즘으로 예측하는 경우에도 데이터의 구성에 따라 정확도 결과는 78.77%로 매우 높게 나올 수 있음\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- MNIST 데이터 세트를 변환하여 불균형한 데이터 세트를 만든 뒤 정확도 지표 적용시 어떤 문제가 발생할 수 있는지 살펴보기\n",
        "\n",
        "- **MNIST 데이터세트** : 0부터 9까지의 숫자 이미지의 픽셀 정보를 가지고 있으며, 이를 기반으로 숫자 Digit을 예측하는데 사용\n",
        "  - 0부터 9까지의 멀티레이블이지만 레이블 값이 7인 것만 True, 나머지는 False인 불균형한 데이터 세트로 변환\n",
        "  - 이후에 모든 데이터를 False(0)으로 예측하는 분류기를 만들어 정확도를 측정\n",
        "결과적으로 아무것도 하지 않고, 특정 결과로만 결과를 반환해도 정확도가 높게 측정되어 모델 성능이 높게 나타나는 현상이 발생"
      ],
      "metadata": {
        "id": "jHbfdomALwEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class MyFakeClassifier(BaseEstimator):\n",
        "  def fit(self, X, y):\n",
        "    pass\n",
        "\n",
        "  # 입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0값으로 만들어서 반환\n",
        "  def predict(self, X):\n",
        "    return np.zeros((len(X),1),dtype=bool)\n",
        "\n",
        "# 사이킷런의 내장 데이터 셋인 load_digits()를 이용하여 MNIST 데이터 로딩\n",
        "digits = load_digits()\n",
        "\n",
        "# digits 번호가 7이면 True이고 이를 astype(int)로 1로 변환, 7이 아니면 False이고 0으로 변환\n",
        "y=(digits.target == 7).astype(int)\n",
        "\n",
        "# 훈련셋, 테스트셋으로 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)"
      ],
      "metadata": {
        "id": "yNKaHvZdLcu4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불균형한 레이블 데이터 분포도 확인\n",
        "print('레이블 테스트 데이터 크기: ', y_test.shape)\n",
        "print('테스트 데이터 세트 레이블 0과 1의 분포도: ')\n",
        "print(pd.Series(y_test).value_counts())\n",
        "\n",
        "# FakeClassifier를 통해 학습/예측/정확도 평가\n",
        "fakeclf = MyFakeClassifier()\n",
        "fakeclf.fit(X_train, y_train)\n",
        "fake_prediction = fakeclf.predict(X_test)\n",
        "print('모든 예측을 0으로 했을 때의 정확도: ', accuracy_score(y_test, fake_prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BLoBaTrLuA3",
        "outputId": "aaafe3b2-349f-4700-c927-528cb6d13720"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "레이블 테스트 데이터 크기:  (450,)\n",
            "테스트 데이터 세트 레이블 0과 1의 분포도: \n",
            "0    405\n",
            "1     45\n",
            "dtype: int64\n",
            "모든 예측을 0으로 했을 때의 정확도:  0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**02. 오차 행렬(Confusion matrix)**"
      ],
      "metadata": {
        "id": "UM7ViqXoNfAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측을 수행하면서 얼마나 헷갈리고 있는지도 함께 보여주는 지표\n",
        "\n",
        "**오차행렬**\n",
        ": 4분면으로 나누어 왼쪽, 오른쪽을 예측된 클래스 값 기준으로 Negative와 Positive로 분류, 위 아래를 실제 클래스 값 기준으로 Negative와 Positive로 분류\n",
        "\n",
        "- TN: True Negative\n",
        "- FP: False Positive\n",
        "- FN: False Negative\n",
        "- TP: True Positive"
      ],
      "metadata": {
        "id": "0a2fEdzBNQy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#사이킷런의 오차행렬 API: confusion_matrix()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test,fakepred)"
      ],
      "metadata": {
        "id": "qL3PpJBRav_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정확도 = 예측 결과와 실제 값이 동일한 건수/전체 데이터 수 = (TN + TP)/(TN + FP + FN + TP)**\n",
        "\n",
        "Positive 양성으로 1, Negatie 음성으로 0 값을 각각 할당\n",
        "\n",
        "불균형한 이진 분류 데이터 세트에서는 Positice 데이터 건수가 매우 작기 때문에 Negative로 예측 정확도가 높아지는 경향이 발생"
      ],
      "metadata": {
        "id": "NlI6Ddx2OOmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **03. 정밀도와 재현율**\n",
        "\n",
        "Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춤\n",
        "\n",
        "**정밀도 = TP / (FP + TP)**\n",
        "\n",
        "**재현율 = TP / (FN + TP)**\n",
        "\n",
        "정밀도는 예측을 Positive로 한 대상 중 예측과 실제 값이 Positive로 일치한 데이터 비율\n",
        "\n",
        "재현율은 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터 비율"
      ],
      "metadata": {
        "id": "09Oqli8aOZ93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#오차 행렬 및 정밀도, 재현율을 모두 구해서 예측 성능을 평가\n",
        "#사이킷런의 정밀도 계산: precision_score()\n",
        "#재현율 계산: recall_score()\n",
        "#평가 간편 적용:get_clf_eval()\n",
        "\n",
        "from sklearn.metrics import accuracy_score,precision_score,precision_score,recall_score,confusion_matrix\n",
        "\n",
        "def get_clf_eval(y_test,pred):\n",
        "  confusion=confusion_matrix(y_test,pred)\n",
        "  accuracy=accuracy_score(y_test,pred)\n",
        "  precision=precision_score(y_test,pred)\n",
        "  recall=recall_score(y_test,pred)\n",
        "  print('오차 행렬')\n",
        "  print(confusion)\n",
        "  print('정확도:{0:.4f},정밀도:{1:.4f},재현율:{2:.4f}'.format(accuracy,precision,recall))"
      ],
      "metadata": {
        "id": "VKxZk1JBN2JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
        "titanic_df=pd.read_csv('./titanic_train.csv')\n",
        "y_titanic_df=titanic_df['Survived']\n",
        "X_titanic_df=titanic_df.drop('Survived',axis=1)\n",
        "X_titanic_df=transform_features(X_titanic_df)\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X_titanic_df,y_titanic_df,test_size=0.20,random_state=11)\n",
        "\n",
        "lr_clf=LogisticRegression()\n",
        "\n",
        "lr_clf.fit(X_train,y_train)\n",
        "pred=lr_clf.predict(X_test)\n",
        "get_clf_eval(y_test,pred)"
      ],
      "metadata": {
        "id": "c0nwWXVpN5dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **정밀도/재현율 트레이드오프**\n",
        "\n",
        "정밀도와 재현율은 상호 보완적인 평가 지표이므로 한쪽을 강제로 높이면 다른 하나는 수치가 떨어짐\n",
        "\n",
        "사이킷런의 분류 알고리즘은 각각 레이블별 결정 확률을 구하고 더 큰 확률을 가진 것을 예측값으로 함\n",
        "\n",
        "**predict_proba( )**: 예측 확률을 반환"
      ],
      "metadata": {
        "id": "xXCPyaenN7J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_proba=lr_clf.predict_proba(X_test)\n",
        "pred=lr_clf.predict(X_test)\n",
        "print('pred_proba( ) 의 결과 Shape: {0}'.format(pred_proba.shape))\n",
        "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
        "\n",
        "pred_proba_result=np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)\n",
        "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
      ],
      "metadata": {
        "id": "m0I87tgOO3fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "X=[[1, -1, 2],\n",
        "   [2, 0, 0],\n",
        "   [0, 1.1, 1.2]]\n",
        "\n",
        "binarizer=Binarizer(threshold=1.1)\n",
        "print(binarizer.fit_transform(X))\n",
        "#1.1보다 크면 1을 갖도록"
      ],
      "metadata": {
        "id": "ZEcX1yVPO-xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "custom_threshold=0.5\n",
        "\n",
        "pred_proba_1=pred_proba[:,1].reshape(-1,1)\n",
        "\n",
        "binarizer=Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
        "custom_predict=binarizer.transform(pred_proba_1)\n",
        "\n",
        "get_clf_eval(y_test, custom_predict)"
      ],
      "metadata": {
        "id": "--VNcKHyO_HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#임곗값을 0.4로\n",
        "custom_threshold=0.4\n",
        "\n",
        "pred_proba_1=pred_proba[:,1].reshape(-1,1)\n",
        "\n",
        "binarizer=Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
        "custom_predict=binarizer.transform(pred_proba_1)\n",
        "\n",
        "get_clf_eval(y_test, custom_predict)"
      ],
      "metadata": {
        "id": "AWq55R1oPA_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds=[0.4, 0.45, 0.5, 0.55, 0.6]"
      ],
      "metadata": {
        "id": "vFu7q7G6PCnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
        "  for custom_threshold in thresholds:\n",
        "    binarizer=Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
        "    custom_predict=binarizer.transform(pred_proba_c1)\n",
        "    print('임곗값:', custom_threshold)\n",
        "    get_clf_eval(y_test,custom_predict)\n",
        "\n",
        "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
      ],
      "metadata": {
        "id": "FpRtBWSNPEed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "#레이블 값이 1일 때의 예측 확률을 추출\n",
        "pred_proba_class1=lr_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "#실제값 데이터 세트와 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
        "print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)\n",
        "\n",
        "#반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임계값을 15 Step으로 추출\n",
        "thr_index=np.arange(0, thresholds.shape[0], 15)\n",
        "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
        "print('샘플용 10개의 임곗값:', np.round(thresholds[thr_index],2))\n",
        "\n",
        "#15step 단위로 추출된 임계값에 따른 정밀도와 재현율 값\n",
        "print('샘플 임계값별 정밀도:', np.round(precisions[thr_index],3))\n",
        "print('샘플 임계값별 재현율:', np.round(recalls[thr_index],3))\n"
      ],
      "metadata": {
        "id": "5jyuHM5kPGe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "WBqqmJcpPIyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
        "  precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
        "\n",
        "  plt.figure(figsize=(8,6))\n",
        "  threshold_boundary=thresholds.shape[0]\n",
        "  plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='-', label='precsion')\n",
        "  plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
        "\n",
        "  start, end=plt.xlim()\n",
        "  plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
        "\n",
        "  plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
        "  plt.legend( ); plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:,1])"
      ],
      "metadata": {
        "id": "x4CIqM9JPKWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **정밀도와 재현율의 맹점**\n",
        "\n",
        "임곗값을 변경함에 따라 정밀도와 재현율의 수치가 변경됨\n",
        "-> 그러므로 두 개의 수치를 상호 보완할 수 있는 수준에서 적용\n",
        "\n",
        "- 정밀도 100%가 되는 방법\n",
        "\n",
        ":확실한 기준이 되는 경우만 Positice로 에측하고 나머지는 모두 Negative로 예측\n",
        "\n",
        "FP=0, TP=1\n",
        "\n",
        "- 재현율이 100%가 되는 방법\n",
        "\n",
        ": 모든 환자를 Positive로 예측\n",
        "\n",
        "TP=30, FN=0"
      ],
      "metadata": {
        "id": "vQXI1ApHPP7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **04. F1 스코어**\n",
        "\n",
        "- 정밀도와 재현율을 결합한 지표\n",
        "- 정밀도와 재현율이 어느 한 쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가짐"
      ],
      "metadata": {
        "id": "rtVFTiS4PVQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1=f1_score(y_test, pred)\n",
        "print('F1 스코어: {0:.4f}'.format(f1))"
      ],
      "metadata": {
        "id": "kwKWrznxPZd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get_clf_eval() 함수에 F1 스코어 추가\n",
        "\n",
        "def get_clf_eval(y_test, pred):\n",
        "  confusion=confusion_matrix(y_test, pred)\n",
        "  accuracy=accuracy_score(y_test, pred)\n",
        "  precision=precision_score(y_test, pred)\n",
        "  recall=recall_score(y_test, pred)\n",
        "\n",
        "  f1=f1_score(y_test, pred)\n",
        "  print('오차 행렬')\n",
        "  print(confusion)\n",
        "\n",
        "  print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
        "\n",
        "thresholds=[0.4, 0.45, 0.5, 0.55, 0.6]\n",
        "pred_proba=lr_clf.predict_proba(X_test)\n",
        "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
      ],
      "metadata": {
        "id": "K7NRcVwRPZzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **05. ROC 곡선과 AUC**\n",
        "\n",
        "- ROC 곡선: 수신자 판단 곡선, FPR을 X축, TPR을 Y축으로\n",
        "- TPR=True Positive Rate=재현율, 민감도=**TP/(FN + TP)**\n",
        "- TNR=True Negative Rate=특이성=**TN/(FP + TN)**\n",
        "- FPR=False Positive Rate= 1- 특이성=**FP/(FP + TN)**\n",
        "\n",
        "---\n",
        "\n",
        "ROC 곡선은 대각선으로 이은 직선과 멀수록 성능이 좋고 가까울수록 성능이 안좋음\n",
        "\n",
        "FPR을 변경하면서 TPR의 변화 값을 구함\n",
        "\n",
        "FPR=0 : 임곗값이 1 = positive로 예측하는 경우가 없으므로 FP=0\n",
        "\n",
        "FPR=1 : 임곗값이 0 = 전부 positive로 예측하므로 TN=0이 됨\n",
        "\n",
        "---\n",
        "### **roc_curve( )**:\n",
        "\n",
        "- 입력 파라미터: y_true: 실제 클래스 값 arrary, y_score: predict_prova의 반환 값\n",
        "- 반환값: fpr, thresholds\n"
      ],
      "metadata": {
        "id": "qNk8CDMoPfnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "pred_proba_class1=lr_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "fprs, tprs, thresholds=roc_curve(y_test, pred_proba_class1)\n",
        "\n",
        "thr_index=np.arange(0, thresholds.shape[0],5)\n",
        "#결과값이 똑같이 나오려면 0부터 시작해야하는데 왜 교재에는 1부터 시작하는가?..\n",
        "\n",
        "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
        "print('샘플용 10개의 임곗값: ',np.round(thresholds[thr_index],2))\n",
        "\n",
        "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index],3))\n",
        "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index],3))"
      ],
      "metadata": {
        "id": "NX6qgu8LPgJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roc_curve_plot(y_test, pred_proba_c1):\n",
        "  # 임곘값에 따른 FPR, TPR 값을 반환받음\n",
        "  fprs, tprs, thresholds=roc_curve(y_test, pred_proba_c1)\n",
        "  # ROC 곡선을 그래프 곡선으로 그림\n",
        "  plt.plot(fprs, tprs, label='ROC')\n",
        "  # 가운데 대각선 직선을 그림\n",
        "  plt.plot([0,1],[0,1], 'k--', label='Random')\n",
        "\n",
        "  # FPR X 축의 Scale을 0.1 단위로 변경, X, Y축 명 설정 등\n",
        "  start, end = plt.xlim()\n",
        "  plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
        "  plt.xlim(0,1); plt.ylim(0,1)\n",
        "  plt.xlabel('FPR( 1 - Sensitivity)'); plt.ylabel('TPR( Recall )')\n",
        "  plt.legend()\n",
        "\n",
        "roc_curve_plot(y_test, pred_proba[:,1])"
      ],
      "metadata": {
        "id": "FyH5EsIiPi9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "#기존의 교재에 있는 y_target, preds가 뭔지 모르겠습니다.\n",
        "\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print('정확도: ', np.round(accuracy_score(y_test, pred), 4))\n",
        "print('정밀도: ', np.round(precision_score(y_test, pred), 4))\n",
        "print('재현율: ', np.round(recall_score(y_test, pred), 4))"
      ],
      "metadata": {
        "id": "o6w8jyDvPl1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get_clf_eval에 ROC AUC 값추가\n",
        "\n",
        "def get_clf_eval(y_test, pred):\n",
        "  confusion=confusion_matrix(y_test, pred)\n",
        "  accuracy=accuracy_score(y_test, pred)\n",
        "  precision=precision_score(y_test, pred)\n",
        "  recall=recall_score(y_test, pred)\n",
        "  f1=f1_score(y_test, pred)\n",
        "\n",
        "  roc_auc=roc_auc_score(y_test, pred_proba)\n",
        "  print('오차 행렬')\n",
        "  print(confusion)\n",
        "\n",
        "  print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
      ],
      "metadata": {
        "id": "TbmNQwmrPnr5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}